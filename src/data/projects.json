[
    {
        "id": 0,
        "title": "Stereo Depth Estimation with ESP32-CAM",
        "summary": "Real-time depth map generation using dual ESP32-CAM modules for low-cost 3D perception.",
        "image": "/project_photos/esp32_sterio_vision.jpg",
        "details": {
            "overview": "Built a stereo vision system using two synchronized ESP32-CAM modules to generate real-time depth maps for robotics and embedded applications.",
            "researchQuestion": "Can low-cost ESP32-CAM modules produce reliable depth estimates for practical embedded vision applications?",
            "challenges": [
                "Precise stereo camera calibration",
                "Frame synchronization between modules",
                "Disparity computation on constrained hardware",
                "Rectification and lens distortion correction"
            ],
            "methodology": "Implemented stereo calibration using chessboard patterns. Applied Semi-Global Block Matching (SGBM) algorithm for disparity computation. Optimized pipeline for real-time performance on embedded systems.",
            "technologies": [
                "ESP32-CAM",
                "OpenCV",
                "Stereo Vision",
                "Python",
                "Embedded Systems"
            ],
            "results": "Achieved real-time depth estimation at 10+ FPS with centimeter-level accuracy for indoor environments.",
            "futureWork": "Integration with ROS for autonomous navigation and obstacle avoidance."
        }
    },
    {
        "id": 1,
        "title": "Real-Time 3D Relighting System",
        "summary": "Physically-based rendering pipeline with WebGPU for realistic light-matter interaction on 2D photographs.",
        "image": "/project_photos/3d_relight.png",
        "details": {
            "overview": "Engineered a physically-based rendering (PBR) pipeline using GGX specular distribution, Fresnel-Schlick reflectance, and HBAO (Horizon-Based Ambient Occlusion) to simulate realistic light-matter interaction on 2D photographs.",
            "researchQuestion": "Can we achieve real-time, photorealistic relighting of 2D images using modern GPU compute shaders?",
            "challenges": [
                "Implementing physically accurate lighting models in WebGPU",
                "Dithered ray-marching for artifact-free soft shadows",
                "Integrating ML depth estimation with graphics pipeline"
            ],
            "methodology": "Implemented a dithered ray-marching soft shadow algorithm (48-step) with pseudo-random per-pixel offset and 9-tap Gaussian depth smoothing. Integrated monocular depth estimation (Depth Anything V2) and semantic segmentation (SegFormer B0) via Transformers.js for real-time 3D scene reconstruction from single 2D images.",
            "technologies": [
                "WebGPU",
                "WebGL2",
                "GLSL",
                "Three.js",
                "Transformers.js"
            ],
            "results": "Real-time 3D relighting with realistic shadows and reflections from single 2D images.",
            "futureWork": "Expanding to video relighting and global illumination support."
        }
    },
    {
        "id": 2,
        "title": "Ultra-Low Latency Virtual Piano",
        "summary": "Vision-driven HCI with <5ms latency markerless hand tracking for seamless musical interaction.",
        "details": {
            "overview": "Created an interactive application that allows users to play a virtual piano using hand movements captured by a webcam with ultra-low latency.",
            "researchQuestion": "How to achieve sub-5ms latency in vision-based musical instrument interfaces?",
            "challenges": [
                "Precise fingertip detection with minimal latency",
                "Velocity-based triggering for expressive playing",
                "Bridging computer vision and tactile musical expression"
            ],
            "methodology": "Engineered a markerless motion capture system tracking 21 hand landmarks with <5ms latency. Developed velocity-based triggering algorithms to simulate key-press intensity, bridging the gap between computer vision tracking and tactile musical expression.",
            "technologies": [
                "OpenCV",
                "MediaPipe",
                "aPipe",
                "Python",
                "HCI"
            ],
            "results": "Real-time responsive virtual instrument with <5ms latency enabling seamless musical interaction.",
            "futureWork": "Adding gesture control for volume, sustain pedal, and multi-instrument support."
        }
    },
    {
        "id": 3,
        "title": "Sparse-View Dynamic 3D Reconstruction",
        "summary": "Low-cost volumetric capture using Gaussian Splatting with heterogeneous smartphone array.",
        "details": {
            "overview": "Designed a low-cost volumetric capture pipeline using a heterogeneous array of three smartphone sensors for dynamic 3D reconstruction.",
            "researchQuestion": "Can consumer smartphones replace expensive multi-camera rigs for dynamic 3D capture?",
            "challenges": [
                "Temporal synchronization of un-genlocked devices",
                "Color calibration across different camera ISPs",
                "Sparse-view reconstruction quality"
            ],
            "methodology": "Solved temporal synchronization of un-genlocked devices using audio-waveform alignment algorithms. Implemented histogram matching to unify RGB distributions across disparate camera ISPs.",
            "technologies": [
                "Python",
                "Google Colab",
                "Gaussian Splatting",
                "3D Reconstruction"
            ],
            "results": "Functional dynamic 3D reconstruction from just three smartphone cameras.",
            "futureWork": "Real-time streaming and integration with AR/VR displays."
        }
    },
    {
        "id": 4,
        "title": "FITLIFE - Exercise Tracking & Guidance",
        "summary": "Smart India Hackathon 2023 Winner. Custom pose estimation and exercise tracking web app.",
        "image": "/project_photos/FITLIFE_.jpg",
        "details": {
            "overview": "Developed a comprehensive web application for real-time exercise tracking using computer vision. The system provides guidance and feedback to users to ensure proper form.",
            "researchQuestion": "How can browser-based pose estimation be optimized for real-time feedback on commodity hardware?",
            "challenges": [
                "Real-time pose estimation latency in browser",
                "Accurate form correction logic",
                "Cross-device compatibility"
            ],
            "methodology": "Utilized custom ML models for pose detection and analyzed keypoints to provide corrective feedback.",
            "technologies": [
                "Machine Learning",
                "Pose Estimation",
                "Web Development",
                "Python"
            ],
            "results": "Won Smart India Hackathon 2023. Accurate counting and form analysis for multiple exercises.",
            "futureWork": "Expanding to more complex compound movements and mobile app integration."
        }
    },
    {
        "id": 5,
        "title": "Polyp Segmentation Using UNet 3+",
        "summary": "Medical imaging segmentation achieving 92% IoU and 90% Dice Coefficient.",
        "details": {
            "overview": "Built a refined UNet 3+ architecture for the precise segmentation of polyps in colonoscopy images, critical for early cancer detection.",
            "researchQuestion": "Does UNet 3+ offer significant improvements over standard UNet for variable-sized polyp segmentation?",
            "challenges": [
                "High class imbalance in medical datasets",
                "Variability in polyp size and texture",
                "Generalization to unseen data"
            ],
            "methodology": "Implemented UNet 3+ with deep supervision. Preprocessed medical datasets to normalize lighting and scale.",
            "technologies": [
                "TensorFlow",
                "UNet 3+",
                "Medical Imaging",
                "Python"
            ],
            "results": "Achieved 92% IoU and 90% Dice Coefficient, outperforming baseline models.",
            "futureWork": "Testing on video data for real-time colonoscopy assistance."
        }
    },
    {
        "id": 6,
        "title": "Self-Driving using Reinforcement Learning",
        "summary": "Autonomous vehicle navigation trained with Deep Q-Learning in simulated environments.",
        "details": {
            "overview": "Developed an autonomous driving agent using reinforcement learning techniques, trained in simulation to navigate roads, avoid obstacles, and follow traffic rules.",
            "researchQuestion": "Can deep reinforcement learning agents learn robust driving policies transferable to real-world scenarios?",
            "challenges": [
                "Designing effective reward functions",
                "Handling sparse reward signals",
                "Sim-to-real transfer challenges",
                "Training stability with deep Q-networks"
            ],
            "methodology": "Implemented Deep Q-Network (DQN) with experience replay and target networks. Trained the agent in CARLA/custom simulation environment with continuous state space and discrete action space.",
            "technologies": [
                "Deep Q-Learning",
                "PyTorch",
                "OpenAI Gym",
                "Reinforcement Learning",
                "Simulation"
            ],
            "results": "Agent successfully learned to navigate simulated roads with 85%+ success rate on test tracks.",
            "futureWork": "Implementing PPO and testing on physical RC car platform."
        }
    }
]